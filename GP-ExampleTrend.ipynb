{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Regression - Trend Fitting with a RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF, ExpSineSquared, RationalQuadratic, WhiteKernel\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from ipywidgets import interact\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisless data\n",
    "\n",
    "We fit a GRP to noiless data with a linear/quadratic trend using a single RBF kernel. For larger length scales, the fit better approximates the linear/quadratic trend. This comes at a cost however. To see we can we expand the mean function $m(x)$ as linear combination of kernel functions\n",
    "$$m(x) = \\sum_{i=1}^n \\alpha_i k(x,x_i)$$\n",
    "with $k(x,y)$ the kernel function and $\\vec{\\alpha} = (K+\\sigma_n^2 I)^{-1} \\vec{y}$ the weight vector in the dual space. For larger and larger length scales $K(x,y)\\rightarrow$ resulting the \"weights\" $\\alpha_i$ to blow up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_lin_gp(length_scale, type ='linear'):\n",
    "    x_train = np.linspace(-5,5,6)\n",
    "\n",
    "    if type == 'linear':\n",
    "        y_train = x_train\n",
    "    elif type == 'quadratic':\n",
    "        y_train = x_train**2\n",
    "    else:\n",
    "        raise ValueError('Type: {type} not supported')\n",
    "    \n",
    "    y_train = y_train - y_train.mean()\n",
    "\n",
    "    y_range = np.array([y_train.min(), y_train.max()])\n",
    "\n",
    "    x_pred = np.linspace(-15,15,100)\n",
    "\n",
    "    X = x_train.reshape(-1,1)\n",
    "    Xp = x_pred.reshape(-1,1)\n",
    "\n",
    "    rbf_kernel = RBF(length_scale=length_scale,length_scale_bounds='fixed')\n",
    "    gp = GaussianProcessRegressor(kernel=rbf_kernel, normalize_y=False, alpha = 1e-6)\n",
    "    gp.fit(X, y_train)\n",
    "\n",
    "    y_mean_pred, y_std_pred = gp.predict(Xp, return_std=True)\n",
    "\n",
    "    K_XpX = gp.kernel_(Xp,X)\n",
    "    rbfs = (K_XpX.T * gp.alpha_[:,None])\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    ax1.scatter(x_train, y_train, label = 'data')\n",
    "    ax1.plot(x_pred,y_mean_pred, label = 'm(x)')\n",
    "    \n",
    "    ax1.set_ylim(2*y_range)\n",
    "    ax1.legend()\n",
    "    ax1.set_ylabel('y')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax1.fill_between(\n",
    "        x_pred,\n",
    "        y_mean_pred - y_std_pred,\n",
    "        y_mean_pred + y_std_pred,\n",
    "        color=\"tab:blue\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    for rbf in rbfs:\n",
    "        ax2.plot(x_pred, rbf)\n",
    "    ax2.set_xlabel('x')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d3104819bc4d62874d1874ef780589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.5, description='length_scale', max=5.0, min=0.5, step=0.5), Dropdown…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(example_lin_gp, length_scale=(0.5,5.0,0.5), type=['linear','quadratic']);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "**Top**:\n",
    "The fittted mean function $m(x)$, shaded region is the mean plus/minus one standard deviation\n",
    "\n",
    "**Bottom**:\n",
    "The decomposition of the mean function in terms of the RBFs\n",
    "\n",
    "* For length scales < 2 the data is \"overfitted\", ie it doesn't fit the linear trend\n",
    "* When increasing the length scale, the fit improves (closer matched the linear/quadratic trend). However as can be seen in the bottom panel the \"weight\" tend to blow up for larger length scales, making the solution less numerically robust.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend with Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.linspace(-5,5,24)\n",
    "y_train = rng.normal(x_train,1.0)\n",
    "y_train = y_train - y_train.mean()\n",
    "\n",
    "y_range = np.array([y_train.min(), y_train.max()])\n",
    "\n",
    "x_pred = np.linspace(-15,15,100)\n",
    "\n",
    "X = x_train.reshape(-1,1)\n",
    "Xp = x_pred.reshape(-1,1)\n",
    "\n",
    "def example_lin_gp_noise(length_scale):\n",
    "\n",
    "    kernel = 1.0**2 * RBF(length_scale=length_scale,length_scale_bounds='fixed') + WhiteKernel(noise_level=1.0**2)\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, normalize_y=False)\n",
    "\n",
    "    gp.fit(X, y_train)\n",
    "\n",
    "    y_mean_pred, y_cov_pred = gp.predict(Xp, return_cov=True)\n",
    "\n",
    "    y_std_pred = np.sqrt(np.diag(y_cov_pred))\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8,4))\n",
    "\n",
    "    ax1.scatter(x_train,y_train)\n",
    "    ax1.plot(x_pred, y_mean_pred)\n",
    "    ax1.set_ylim(1.5*y_range)\n",
    "\n",
    "    ax1.fill_between(\n",
    "        x_pred,\n",
    "        y_mean_pred - y_std_pred,\n",
    "        y_mean_pred + y_std_pred,\n",
    "        color=\"tab:blue\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    x_coor, y_coor = np.meshgrid(x_pred,x_pred)\n",
    "\n",
    "    z_range = np.max(np.abs(y_cov_pred))\n",
    "    ax2.pcolormesh(x_coor,y_coor,-y_cov_pred,cmap='RdBu',vmin=-z_range,vmax=z_range)\n",
    "    ax2.set\n",
    "    ax2.set_title(\"COV(X',X')\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813f6e3cb1f64031acc8abfb489cf493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=5.2, description='length_scale', max=10.0, min=0.5), Output()), _dom_c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(example_lin_gp_noise,length_scale=(0.5,10.0,0.1));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "**Left**:\n",
    "The fittted mean function $m(x)$, shaded region is the mean plus/minus one standard deviation\n",
    "\n",
    "**Right**:\n",
    "The covariance function $cov(x,x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
